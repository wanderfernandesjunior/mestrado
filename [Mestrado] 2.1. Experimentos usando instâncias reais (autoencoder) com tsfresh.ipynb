{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Mestrado] 2.1. Experimentos usando instâncias reais (autoencoder) com tsfresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Principais Referências_**\n",
    "  \n",
    "- **A Realistic and Public Dataset with Rare Undesirable Real Events in Oil Wells** ([link](https://doi.org/10.1016/j.petrol.2019.106223)).\n",
    "- **Github de referência do _benchmark_ proposto por Vargas (2019)** ([link](https://github.com/ricardovvargas/3w_dataset))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas e configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Artifício para alcular tempo total do notebook Jupyter\n",
    "from datetime import datetime \n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "variables": {
     "import datetime;import locale;locale.setlocale(locale.LC_ALL, 'portuguese_brazil');datetime.date.today().strftime('%d de %B de %Y')": "05 de agosto de 2018"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "from math import ceil\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from pyod.models.auto_encoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "variables": {
     "import datetime;import locale;locale.setlocale(locale.LC_ALL, 'portuguese_brazil');datetime.date.today().strftime('%d de %B de %Y')": "05 de agosto de 2018"
    }
   },
   "outputs": [],
   "source": [
    "logging.getLogger('tsfresh').setLevel(logging.ERROR)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "variables": {
     "import datetime;import locale;locale.setlocale(locale.LC_ALL, 'portuguese_brazil');datetime.date.today().strftime('%d de %B de %Y')": "05 de agosto de 2018"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = Path('./', 'data')\n",
    "random_state = 1\n",
    "np.random.seed(random_state)\n",
    "events_names = {0: 'Normal',\n",
    "                1: 'Aumento Abrupto de BSW',\n",
    "                2: 'Fechamento Espúrio de DHSV',\n",
    "                3: 'Intermitência Severa',\n",
    "                4: 'Instabilidade de Fluxo',\n",
    "                5: 'Perda Rápida de Produtividade',\n",
    "                6: 'Restrição Rápida em CKP',\n",
    "                7: 'Incrustação em CKP',\n",
    "                8: 'Hidrato em Linha de Produção'\n",
    "               }\n",
    "vars = ['P-PDG',\n",
    "        'P-TPT',\n",
    "        'T-TPT',\n",
    "        'P-MON-CKP',\n",
    "        'T-JUS-CKP',\n",
    "        'P-JUS-CKGL',\n",
    "        'T-JUS-CKGL',\n",
    "        'QGL']\n",
    "columns = ['timestamp'] + vars + ['class'] \n",
    "normal_class_code = 0\n",
    "abnormal_classes_codes = [1, 2, 5, 6, 7, 8]\n",
    "sample_size = 3*60              # Nas observações = segundos\n",
    "min_normal_period_size = 20*60  # Nas observações = segundos\n",
    "split_range = 0.6               # Porcentagem de separação entre treino/teste\n",
    "max_samples_per_period = 15     # limitação por 'segurança'\n",
    "df_fc_p = MinimalFCParameters() # Ver documentação da biblioteca tsfresh\n",
    "df_fc_p.pop('sum_values')       # Remove feature inapropriada\n",
    "df_fc_p.pop('length')           # Remove feature inapropriada\n",
    "max_nan_percent = 0.1           # Para seleção de variáveis úteis\n",
    "std_vars_min = 0.01             # Para seleção de variáveis úteis\n",
    "clfs = {}                       # Dicionário para lista de classificadores a serem experimentados\n",
    "disable_progressbar = True      # Para menos saídas no notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def class_and_file_generator(data_path, real=False, simulated=False, drawn=False):\n",
    "    \"\"\"Gerador de lista contendo número da classe e caminho do arquivo de acordo com a fonte da instância.\"\"\"    \n",
    "    for class_path in data_path.iterdir():\n",
    "        if class_path.is_dir():\n",
    "            class_code = int(class_path.stem)\n",
    "            for instance_path in class_path.iterdir():\n",
    "                if (instance_path.suffix == '.csv'):\n",
    "                    if (simulated and instance_path.stem.startswith('SIMULATED')) or \\\n",
    "                       (drawn and instance_path.stem.startswith('DRAWN')) or \\\n",
    "                       (real and (not instance_path.stem.startswith('SIMULATED')) and \\\n",
    "                       (not instance_path.stem.startswith('DRAWN'))):\n",
    "                        yield class_code, instance_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_instance(instance_path):\n",
    "    \"\"\"Função que carrega cada instância individualmente\"\"\"\n",
    "    try:\n",
    "        well, instance_id = instance_path.stem.split('_')\n",
    "        df = pd.read_csv(instance_path, sep=',', header=0)\n",
    "        assert (df.columns == columns).all(), \\\n",
    "            f'Colunas inválidas no arquivo {str(instance_path)}: {str(df.columns.tolist())}'\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception(f'Erro ao ler arquivo {instance_path}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_samples(df, class_code):\n",
    "    # Obtém os rótulos das observações e seu conjunto inequívoco\n",
    "    ols = list(df['class'])\n",
    "    set_ols = set()\n",
    "    for ol in ols:\n",
    "        if ol in set_ols or np.isnan(ol):\n",
    "            continue\n",
    "        set_ols.add(int(ol))       \n",
    "    \n",
    "    # Descarta os rótulos das observações e substitui todos os nan por 0\n",
    "    # (requisito da biblioteca tsfresh)\n",
    "    df_vars = df.drop('class', axis=1).fillna(0)  \n",
    "    \n",
    "    # Inicializa objetos que serão retornados\n",
    "    df_samples_train = pd.DataFrame()\n",
    "    df_samples_test = pd.DataFrame()\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "            \n",
    "    # Descubre o número máximo de amostras em períodos normais, transitórios e em regime\n",
    "    # Obtém índices (primeiro e último) sem sobreposição com outros períodos\n",
    "    f_idx = ols.index(normal_class_code)\n",
    "    l_idx = len(ols)-1-ols[::-1].index(normal_class_code)\n",
    "\n",
    "    # Define o número inicial de amostras para o período normal\n",
    "    max_samples_normal = l_idx-f_idx+1-sample_size\n",
    "    if (max_samples_normal) > 0:      \n",
    "        num_normal_samples = min(max_samples_per_period, max_samples_normal)\n",
    "        num_train_samples = int(split_range*num_normal_samples)\n",
    "        num_test_samples = num_normal_samples - num_train_samples    \n",
    "    else:\n",
    "        num_train_samples = 0\n",
    "        num_test_samples = 0\n",
    "    \n",
    "    # Define o número máximo de amostras por período transitório\n",
    "    transient_code = class_code + 100    \n",
    "    if transient_code in set_ols:\n",
    "        # Obtém índices (primeiro e último) com possível sobreposição\n",
    "        # no início do período\n",
    "        f_idx = ols.index(transient_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(transient_code)        \n",
    "        max_transient_samples = l_idx-f_idx+1-sample_size\n",
    "    else:\n",
    "        max_transient_samples = 0            \n",
    "\n",
    "    # Define o número máximo de amostras no período de regime\n",
    "    if class_code in set_ols:\n",
    "        # Obtém índices (primeiro e último) com possível sobreposição \n",
    "        # no início ou fim do período\n",
    "        f_idx = ols.index(class_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(class_code)\n",
    "        if l_idx+(sample_size-1) < len(ols)-1:\n",
    "            l_idx = l_idx+(sample_size-1) \n",
    "        else:\n",
    "            l_idx = len(ols)-1\n",
    "        max_in_regime_samples = l_idx-f_idx+1-sample_size\n",
    "    else:\n",
    "        max_in_regime_samples = 0   \n",
    "        \n",
    "    # Descubre o número adequado de amostras em períodos normais, transitórios e em regime\n",
    "    num_transient_samples = ceil(num_test_samples/2)\n",
    "    num_in_regime_samples = num_test_samples - num_transient_samples\n",
    "    if (max_transient_samples >= num_transient_samples) and \\\n",
    "       (max_in_regime_samples < num_in_regime_samples):\n",
    "        num_in_regime_samples = max_in_regime_samples        \n",
    "        num_transient_samples = min(num_test_samples-num_in_regime_samples, max_transient_samples)\n",
    "    elif (max_transient_samples < num_transient_samples) and \\\n",
    "         (max_in_regime_samples >= num_in_regime_samples):\n",
    "        num_transient_samples = max_transient_samples        \n",
    "        num_in_regime_samples = min(num_test_samples-num_transient_samples, max_in_regime_samples)\n",
    "    elif (max_transient_samples < num_transient_samples) and \\\n",
    "         (max_in_regime_samples < num_in_regime_samples):\n",
    "        num_transient_samples = max_transient_samples\n",
    "        num_in_regime_samples = max_in_regime_samples\n",
    "        num_test_samples = num_transient_samples+num_in_regime_samples\n",
    "    \n",
    "    # Extrai amostras do período normal para treinamento e teste\n",
    "    # Obtém índices (primeiro e último) sem sobreposição com outros períodos\n",
    "    f_idx = ols.index(normal_class_code)\n",
    "    l_idx = len(ols)-1-ols[::-1].index(normal_class_code)\n",
    "    \n",
    "    # Define a etapa correta e extrai amostras\n",
    "    if (num_normal_samples) > 0:  \n",
    "        if num_normal_samples == max_samples_normal:\n",
    "            step_max = 1 \n",
    "        else:\n",
    "            step_max = (max_samples_normal-1) // (max_samples_per_period-1)\n",
    "        step_wanted = sample_size\n",
    "        step = min(step_wanted, step_max)\n",
    "        \n",
    "        # Extrai amostras para treinamento\n",
    "        sample_id = 0\n",
    "        for idx in range(num_train_samples):\n",
    "            f_idx_c = l_idx-sample_size+1-(num_normal_samples-1-idx)*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_train = df_samples_train.append(df_sample)\n",
    "            y_train.append(normal_class_code)\n",
    "            sample_id += 1\n",
    "    \n",
    "        # Extrai amostras para teste\n",
    "        sample_id = 0\n",
    "        for idx in range(num_train_samples, num_train_samples+num_test_samples):\n",
    "            f_idx_c = l_idx-sample_size+1-(num_normal_samples-1-idx)*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_test = df_samples_test.append(df_sample)\n",
    "            y_test.append(normal_class_code)\n",
    "            sample_id += 1\n",
    "\n",
    "    # Extrai amostras do período transitório (se existir) para teste\n",
    "    if (num_transient_samples) > 0:    \n",
    "        # Define a etapa correta e extrai amostras\n",
    "        if num_transient_samples == max_transient_samples:\n",
    "            step_max = 1 \n",
    "        else:\n",
    "            step_max = (max_transient_samples-1) // (max_samples_per_period-1)\n",
    "        step_wanted = np.inf\n",
    "        step = min(step_wanted, step_max)\n",
    "        \n",
    "        # Obtém índices (primeiro e último) com possível sobreposição no início deste período\n",
    "        f_idx = ols.index(transient_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(transient_code) \n",
    "\n",
    "        # Extrai amostras\n",
    "        for idx in range(num_transient_samples):\n",
    "            f_idx_c = f_idx+idx*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_test = df_samples_test.append(df_sample)\n",
    "            y_test.append(transient_code)\n",
    "            sample_id += 1\n",
    "            \n",
    "    # Extrai amostras do período em regime (se existir) para teste\n",
    "    if (num_in_regime_samples) > 0:     \n",
    "        # Define a etapa correta e extrai amostras\n",
    "        if num_in_regime_samples == max_in_regime_samples:\n",
    "            step_max = 1 \n",
    "        else:\n",
    "            step_max = (max_in_regime_samples-1) // (max_samples_per_period-1)\n",
    "        step_wanted = sample_size\n",
    "        step = min(step_wanted, step_max)\n",
    "        \n",
    "        # Obtém índices (primeiro e último) com possível sobreposição \n",
    "        # no início ou no final deste período\n",
    "        f_idx = ols.index(class_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(class_code)\n",
    "        if l_idx+(sample_size-1) < len(ols)-1:\n",
    "            l_idx = l_idx+(sample_size-1) \n",
    "        else:\n",
    "            l_idx = len(ols)-1\n",
    "\n",
    "        # Extrai amostras\n",
    "        for idx in range(num_in_regime_samples):\n",
    "            f_idx_c = f_idx+idx*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_test = df_samples_test.append(df_sample)\n",
    "            y_test.append(class_code)\n",
    "            sample_id += 1\n",
    "\n",
    "    return df_samples_train, y_train, df_samples_test, y_test              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_test_calc_scores(X_train, y_train, X_test, y_test, scores, clfs):\n",
    "    for clf_name, clf in clfs.items():\n",
    "        \n",
    "        # Treino\n",
    "        t0 = time()\n",
    "        history = clf.fit(X_train, y_train)\n",
    "        t_train = time() - t0\n",
    "\n",
    "        # Teste\n",
    "        t0 = time()\n",
    "        y_pred = clf.predict(X_test)\n",
    "        t_test = time() - t0         \n",
    "\n",
    "        # Calcula as metricas de desempenho\n",
    "        ret = precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "        p, r, f1, _ = ret\n",
    "        #print(f'f1: \\t {f1}')\n",
    "        scores = scores.append({'CLASSIFICADOR': clf_name, \n",
    "                                'PRECISAO': p,\n",
    "                                'REVOGACAO': r,\n",
    "                                'F1': f1,\n",
    "                                'TREINAMENTO [s]': t_train, \n",
    "                                'TESTE [s] ': t_test}, ignore_index=True)  \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gets all selected instances but maintains only those with any type of undesirable event\n",
    "real_instances = pd.DataFrame(class_and_file_generator(data_path, \n",
    "                                                       real=True,\n",
    "                                                       simulated=False, \n",
    "                                                       drawn=False),\n",
    "                              columns=['class_code', 'instance_path'])\n",
    "real_instances = real_instances.loc[real_instances.iloc[:,0].isin(abnormal_classes_codes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância 1: data\\1\\WELL-00001_20140124213136.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (959)\n",
      "\n",
      "Instância 2: data\\1\\WELL-00002_20140126200050.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (1138)\n",
      "\n",
      "Instância 3: data\\1\\WELL-00006_20170801063614.csv\n",
      "Instância 4: data\\1\\WELL-00006_20170802123000.csv\n",
      "Instância 5: data\\1\\WELL-00006_20180618060245.csv\n",
      "Instância 6: data\\2\\WELL-00002_20131104014101.csv\n",
      "Instância 7: data\\2\\WELL-00003_20141122214325.csv\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188837931F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 8: data\\2\\WELL-00003_20170728150240.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188837313A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 9: data\\2\\WELL-00003_20180206182917.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (586)\n",
      "\n",
      "Instância 10: data\\2\\WELL-00009_20170313160804.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188839D1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 11: data\\2\\WELL-00010_20171218200131.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018883B02820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 12: data\\2\\WELL-00011_20140515110134.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188838DAEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 13: data\\2\\WELL-00011_20140530100015.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (482)\n",
      "\n",
      "Instância 14: data\\2\\WELL-00011_20140606230115.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018888DAE0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 15: data\\2\\WELL-00011_20140720120102.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001887651C430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 16: data\\2\\WELL-00011_20140726180015.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (900)\n",
      "\n",
      "Instância 17: data\\2\\WELL-00011_20140824000118.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018888F7ACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 18: data\\2\\WELL-00011_20140916060300.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888391A670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 19: data\\2\\WELL-00011_20140921200031.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (695)\n",
      "\n",
      "Instância 20: data\\2\\WELL-00011_20140928100056.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018887785700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 21: data\\2\\WELL-00011_20140929170028.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (975)\n",
      "\n",
      "Instância 22: data\\2\\WELL-00011_20140929220121.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188852A1F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 23: data\\2\\WELL-00011_20141005170056.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188853821F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 24: data\\2\\WELL-00011_20141006160121.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188853820D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 25: data\\2\\WELL-00012_20170320033022.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (773)\n",
      "\n",
      "Instância 26: data\\2\\WELL-00012_20170320143144.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188765CACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 27: data\\2\\WELL-00013_20170329020229.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018880E9D310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 28: data\\5\\WELL-00015_20170620160349.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188853821F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 29: data\\5\\WELL-00015_20171013140047.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888A858040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 30: data\\5\\WELL-00016_20180405020345.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (1145)\n",
      "\n",
      "Instância 31: data\\5\\WELL-00016_20180426142005.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (321)\n",
      "\n",
      "Instância 32: data\\5\\WELL-00016_20180426145108.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (376)\n",
      "\n",
      "Instância 33: data\\5\\WELL-00016_20180517222322.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188759474C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 34: data\\5\\WELL-00017_20140314180000.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (0)\n",
      "\n",
      "Instância 35: data\\5\\WELL-00017_20140317151743.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018887BCAAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância 36: data\\5\\WELL-00017_20140318023141.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188765ED4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 37: data\\5\\WELL-00017_20140318160220.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018887785430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 38: data\\5\\WELL-00017_20140319040453.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188876D78B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 39: data\\5\\WELL-00017_20140319141450.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188766DE790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 40: data\\6\\WELL-00002_20140212170333.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888B298040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 41: data\\6\\WELL-00002_20140301151700.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018880E9D160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 42: data\\6\\WELL-00002_20140325170304.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188766160D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 43: data\\6\\WELL-00004_20171031181509.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888773D0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 44: data\\6\\WELL-00004_20171031193025.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (414)\n",
      "\n",
      "Instância 45: data\\6\\WELL-00004_20171031200059.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (845)\n",
      "\n",
      "Instância 46: data\\7\\WELL-00001_20170226220309.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018883D51B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 47: data\\7\\WELL-00006_20180618110721.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888391AF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instância 48: data\\7\\WELL-00006_20180620181348.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000188766161F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 49: data\\7\\WELL-00018_20180611040207.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (0)\n",
      "\n",
      "Instância 50: data\\8\\WELL-00019_20170301182317.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018883D51820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Instância 51: data\\8\\WELL-00020_20120410192326.csv\n",
      "\tignorado porque normal_period_size é insuficiente para treinamento (173)\n",
      "\n",
      "Instância 52: data\\8\\WELL-00021_20170509013517.csv\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001888B536EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# For each real instance with any type of undesirable event\n",
    "scores = pd.DataFrame()\n",
    "ignored_instances = 0\n",
    "used_instances = 0\n",
    "for i, row in real_instances.iterrows():\n",
    "    # Loads the current instance\n",
    "    class_code, instance_path = row\n",
    "    print(f'Instância {i+1}: {instance_path}')\n",
    "    df = load_instance(instance_path)\n",
    "    \n",
    "    # Ignores instances without sufficient normal periods\n",
    "    normal_period_size = (df['class']==float(normal_class_code)).sum()\n",
    "    if normal_period_size < min_normal_period_size:\n",
    "        ignored_instances += 1\n",
    "        print(f'\\tignorado porque normal_period_size é insuficiente para treinamento ({normal_period_size})\\n')\n",
    "        continue\n",
    "    used_instances += 1\n",
    "        \n",
    "    # Extracts samples from the current real instance\n",
    "    ret = extract_samples(df, class_code)\n",
    "    df_samples_train, y_train, df_samples_test, y_test = ret\n",
    "\n",
    "    # Changes types of the labels (tsfresh's requirement)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # We want binary classification: 0 stands for inliers and 1 for outliers/anomalies\n",
    "    # (pyod's requirement)\n",
    "    y_train[y_train!=normal_class_code] = 1\n",
    "    y_train[y_train==normal_class_code] = 0   \n",
    "    y_test[y_test!=normal_class_code] = 1\n",
    "    y_test[y_test==normal_class_code] = 0\n",
    "    \n",
    "    # Drops the bad vars\n",
    "    good_vars = np.isnan(df_samples_train[vars]).mean(0) <= max_nan_percent\n",
    "    std_vars = np.nanstd(df_samples_train[vars], 0)\n",
    "    good_vars &= (std_vars > std_vars_min)    \n",
    "    good_vars = list(good_vars.index[good_vars])\n",
    "    bad_vars = list(set(vars)-set(good_vars))\n",
    "    df_samples_train.drop(columns=bad_vars, inplace=True, errors='ignore')\n",
    "    df_samples_test.drop(columns=bad_vars, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Normalizes the samples (zero mean and unit variance)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    df_samples_train[good_vars] = scaler.fit_transform(df_samples_train[good_vars]).astype('float32')\n",
    "    df_samples_test[good_vars] = scaler.transform(df_samples_test[good_vars]).astype('float32')\n",
    "    \n",
    "    # Extracts features from samples\n",
    "    X_train = extract_features(df_samples_train, \n",
    "                               column_id='id', \n",
    "                               column_sort='timestamp', \n",
    "                               default_fc_parameters=df_fc_p,\n",
    "                               impute_function=impute,\n",
    "                               n_jobs=0,\n",
    "                               disable_progressbar=disable_progressbar)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = extract_features(df_samples_test, \n",
    "                              column_id='id', \n",
    "                              column_sort='timestamp',\n",
    "                              default_fc_parameters=df_fc_p,\n",
    "                              impute_function=impute,\n",
    "                              n_jobs=0,\n",
    "                              disable_progressbar=disable_progressbar)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Remove a coluna timestamp (não é usada como entrada nos classificadores)\n",
    "    df_samples_train = df_samples_train.drop('timestamp', 1)\n",
    "    df_samples_test = df_samples_test.drop('timestamp', 1)\n",
    "    \n",
    "    # Rearranja o dataframe df_samples_train para que as variáveis estejam em linha\n",
    "    df_samples_train_ajustado = (\n",
    "        df_samples_train.pivot_table(values=None, \n",
    "                                     index='id', \n",
    "                                     columns=df_samples_train.groupby('id').cumcount() + 1, \n",
    "                                     aggfunc='first')\n",
    "        .reset_index()\n",
    "        )\n",
    "    \n",
    "    # (Rearranja o dataframe df_samples_test para que as variáveis estejam em linha\n",
    "    df_samples_test_ajustado = (\n",
    "        df_samples_test.pivot_table(values=None, \n",
    "                                     index='id', \n",
    "                                     columns=df_samples_test.groupby('id').cumcount() + 1, \n",
    "                                     aggfunc='first')\n",
    "        .reset_index()\n",
    "        )\n",
    "    \n",
    "    X_train = df_samples_train_ajustado\n",
    "    X_test = df_samples_test_ajustado\n",
    "    \n",
    "    # Ajustes para completar valores faltantes com zero e remover os multiindexes criados\n",
    "    X_train = X_train.replace(np.nan, 0)\n",
    "    X_test = X_test.replace(np.nan, 0)\n",
    "\n",
    "    X_train.drop('id',  axis='columns', inplace=True)\n",
    "    X_test.drop('id',  axis='columns', inplace=True)\n",
    "\n",
    "    X_train = X_train.droplevel(0, axis=1)\n",
    "    X_test = X_test.droplevel(0, axis=1)\n",
    "\n",
    "    X_train = X_train.T.reset_index(drop=True).T\n",
    "    X_test = X_test.T.reset_index(drop=True).T\n",
    "\n",
    "    X_train.reset_index(inplace=True, drop=True)\n",
    "    X_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Reshape dos dados para formato de entrada da rede LSTM\n",
    "    # que é um array 3D no formato (observações, timesteps, features)\n",
    "    #X_train = X_train.values.reshape(X_train.shape[0], 180, X_train.shape[1] // 180, order='F')\n",
    "    #X_test = X_test.values.reshape(X_test.shape[0], 180, X_test.shape[1] // 180, order='F')\n",
    "    \"\"\"\n",
    "    # LISTA DE CLASSIFICADORES \n",
    "    # Incluido apenas o com melhor resultado nas instancias simuladas\n",
    "        \n",
    "    # AUTOENCODER\n",
    "    clfs['AutoEncoder'] = AutoEncoder(hidden_neurons=[4, 2, 2, 4], hidden_activation='relu', output_activation='sigmoid', \n",
    "                                       loss='mae', optimizer='adam', epochs=10, batch_size=8, \n",
    "                                       dropout_rate=0, l2_regularizer=0.1, validation_size=0.1, preprocessing=False, \n",
    "                                       verbose=0, random_state=random_state, contamination=0.1)\n",
    "    \n",
    "    # Trains, tests and calculates the scores    \n",
    "    scores = train_test_calc_scores(X_train, y_train, X_test, y_test, scores, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados obtidos com os métodos implementados são apresentados abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de instâncias utilizadas: 36\n",
      "Número de instâncias ignoradas: 16\n"
     ]
    }
   ],
   "source": [
    "print(f'Número de instâncias utilizadas: {used_instances}')\n",
    "print(f'Número de instâncias ignoradas: {ignored_instances}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características utilizadas: ['median', 'mean', 'standard_deviation', 'variance', 'root_mean_square', 'maximum', 'minimum']\n"
     ]
    }
   ],
   "source": [
    "print(f'Características utilizadas: {list(df_fc_p.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os comandos a seguir permitem salvar e recuperar os resultados de/para um arquivo CSV de forma conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores.to_csv(r'./results/2-1_anomaly_detection_scores_reais.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas em formato tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tabelas a seguir apresentam as médias e o desvio padrão das métricas, respectivamente. Ambos são ordenados pela medida-F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISAO</th>\n",
       "      <th>REVOGACAO</th>\n",
       "      <th>F1</th>\n",
       "      <th>TREINAMENTO [s]</th>\n",
       "      <th>TESTE [s]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIFICADOR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AutoEncoder</th>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>1.441114</td>\n",
       "      <td>0.045269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRECISAO  REVOGACAO        F1  TREINAMENTO [s]  TESTE [s] \n",
       "CLASSIFICADOR                                                            \n",
       "AutoEncoder    0.590278   0.590278  0.590278         1.441114    0.045269"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Médias\n",
    "mean_score_table = scores.groupby('CLASSIFICADOR').mean().sort_values(by=['F1'], ascending=False)\n",
    "mean_score_table.to_csv(r'./results/2-1_anomaly_detection_scores_medias_reais.csv')\n",
    "mean_score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECISAO</th>\n",
       "      <th>REVOGACAO</th>\n",
       "      <th>F1</th>\n",
       "      <th>TREINAMENTO [s]</th>\n",
       "      <th>TESTE [s]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIFICADOR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AutoEncoder</th>\n",
       "      <td>0.16947</td>\n",
       "      <td>0.16947</td>\n",
       "      <td>0.16947</td>\n",
       "      <td>0.283774</td>\n",
       "      <td>0.04669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRECISAO  REVOGACAO       F1  TREINAMENTO [s]  TESTE [s] \n",
       "CLASSIFICADOR                                                           \n",
       "AutoEncoder     0.16947    0.16947  0.16947         0.283774     0.04669"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Desvios Padrão\n",
    "std_score_table = scores.groupby('CLASSIFICADOR').std().sort_values(by=['F1'], ascending=True)\n",
    "std_score_table.to_csv(r'./results/2-1_anomaly_detection_scores_desvios_padrao_reais.csv')\n",
    "std_score_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado acima será utilizado conjuntamente com o resultado obtido nos classificadores sklearn para avaliação estatística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de execução (hh:mm:ss.ms): 0:01:05.023312\n"
     ]
    }
   ],
   "source": [
    "# Calcular tempo total do notebook Jupyter\n",
    "print(f'Tempo total de execução (hh:mm:ss.ms): {datetime.now() - start_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Sumário",
   "title_sidebar": "Sumário",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
